{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning with TF2 and Keras: chapter 07.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGkIpJkbwQ5gsWzImXhG25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboelela924/Deep-learning-with-TF2-and-Keras/blob/master/Deep_learning_with_TF2_and_Keras_chapter_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJVzouyA7vy5"
      },
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwUDw_fyQNsb"
      },
      "source": [
        "if not os.path.isdir(\"/content/data\"):\n",
        "    os.mkdir(\"/content/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jln1NVaIQY53",
        "outputId": "a34006ef-d64e-410d-8917-eb41c8764ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "dataset = api.load(\"text8\")\n",
        "model = Word2Vec(dataset)\n",
        "\n",
        "model.save(\"data/text8-word2vec.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgWZN5jOQiJ_",
        "outputId": "626ac7cb-41f2-4111-f16e-5406a06638c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load(\"/content/data/text8-word2vec.bin\")\n",
        "word_vectors = model.wv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQhdWNXKSVe1",
        "outputId": "663a6e7d-26fd-4892-c938-cb39fbb5a45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "words = word_vectors.vocab.keys()\n",
        "print([word for i, word in enumerate(words) if i < 10])\n",
        "assert \"king\" in words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QNozy5-SqcA",
        "outputId": "15aff73a-b8ae-412c-e467-8073b6688983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(word_vectors.most_similar(\"king\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('prince', 0.7400096654891968), ('emperor', 0.7214909195899963), ('throne', 0.7093262672424316), ('queen', 0.7061789035797119), ('kings', 0.6803011894226074), ('aragon', 0.675293505191803), ('vii', 0.670933723449707), ('regent', 0.6631604433059692), ('pope', 0.6609975099563599), ('elector', 0.6554006934165955)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKE2aJnBTUIy",
        "outputId": "267fd0cb-797e-4ada-eebf-fa05ef117cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def print_most_similar_words(word_score_pairs, c):\n",
        "    for i, (word, similar_word_score) in enumerate(word_score_pairs):\n",
        "        print(\"{:.3f} {:s}\".format(similar_word_score, word))\n",
        "        if i >= c:\n",
        "            break\n",
        "print_most_similar_words(word_vectors.most_similar(\"king\"), 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.740 prince\n",
            "0.721 emperor\n",
            "0.709 throne\n",
            "0.706 queen\n",
            "0.680 kings\n",
            "0.675 aragon\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxFOvtkt8SZg",
        "outputId": "70195dc1-3bd1-4e7c-dc3d-471882ef948c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print_most_similar_words(word_vectors.most_similar(positive=[\"france\", \"berlin\"], negative=[\"paris\"]), 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.807 germany\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITmq2Mo983Dc",
        "outputId": "0aec5a6f-d69e-4804-b98a-77a548e43f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print_most_similar_words(word_vectors.most_similar_cosmul(positive=[\"france\", \"berlin\"], negative=[\"paris\"]), 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.984 germany\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQNrBqE89XU3",
        "outputId": "976f2ec1-2268-40e4-9439-61f9a0519914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "print(word_vectors.doesnt_match([\"berlin\", \"england\", \"rome\",\"madrid\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "england\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2KriAwL-Rzp",
        "outputId": "3aa6b3c7-646e-4ba8-97b5-76e4e4cf761d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(word_vectors.similar_by_word(\"rice\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('beef', 0.8637088537216187), ('pork', 0.8619951009750366), ('potatoes', 0.8536219596862793), ('tomato', 0.8464804887771606), ('citrus', 0.8418481349945068), ('barley', 0.8387696743011475), ('soy', 0.8323472738265991), ('cereal', 0.8316136598587036), ('onions', 0.8302257657051086), ('peanuts', 0.828937828540802)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMMRYXtAAGHD"
      },
      "source": [
        "<h1>Using word embeddings for spam detection</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBBBermhNWBA",
        "outputId": "43f0962c-3794-4662-bb3f-152797ccf083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=6fc4b00eabbe09eda19c685aefff88639e452f200b66a4ea6d95dd90004faed3\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BNdnGif_9GJ"
      },
      "source": [
        "import argparse \n",
        "import gensim.downloader as api \n",
        "import numpy as np \n",
        "import os \n",
        "import shutil \n",
        "import tensorflow as tf\n",
        "import wget\n",
        "import zipfile\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgJ3rBBAKva7"
      },
      "source": [
        "if not os.path.isdir(\"/content/datasets\"):\n",
        "    os.mkdir(\"/content/datasets\")\n",
        "    os.mkdir(\"/content/datasets/SMSSpamCollection\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyMeGXK1J3J1"
      },
      "source": [
        "def download_and_read(url):\n",
        "    local_file = url.split(\"/\")[-1]\n",
        "    wget.download(url, f\"/content/{local_file}\")\n",
        "\n",
        "    with zipfile.ZipFile(f\"/content/{local_file}\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content\")\n",
        "    labels, texts = [], []\n",
        "    path = f\"/content/SMSSpamCollection\"\n",
        "    with open(path, \"r\") as fin:\n",
        "        for line in fin:\n",
        "            label, text = line.strip().split(\"\\t\")\n",
        "            labels.append(1 if label == \"spam\" else 0)\n",
        "            texts.append(text)\n",
        "    return texts, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6jWU5_yMB5W"
      },
      "source": [
        "DATASET_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "texts, labels = download_and_read(DATASET_URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tMMVIyfMQZi",
        "outputId": "b11e7d43-c695-460c-b57e-8379744401ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "text_sequences = tf.keras.preprocessing.sequence.pad_sequences(text_sequences)\n",
        "\n",
        "print(f\"num of sequences {len(text_sequences)}\")\n",
        "print(f\"length of the max sequence {len(text_sequences[0])}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of sequences 5574\n",
            "length of the max sequence 189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uXbUDF_OQ7T"
      },
      "source": [
        "NUM_CLASSES = 2\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8zm8-MzSLuT",
        "outputId": "62c94cfc-67dc-479e-cb48-6cce4dbacc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "print(labels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzMz_klqSdXZ",
        "outputId": "a4278acb-548e-44fc-8461-4893de84f083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "word2idx = tokenizer.word_index\n",
        "idx2word = {value: key for key, value in word2idx.items()}\n",
        "word2idx[\"PAD\"] = 0\n",
        "idx2word[0] = \"PAD\"\n",
        "vocab_size = len(word2idx)\n",
        "print(\"Vocab size: {:d}\".format(vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 9010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2wuRcRTLyJ"
      },
      "source": [
        "dataset_size = len(text_sequences)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((text_sequences, labels))\n",
        "dataset = dataset.shuffle(1000)\n",
        "\n",
        "test_size = dataset_size // 4\n",
        "val_size = dataset_size // 10\n",
        "\n",
        "val_dataset = dataset.take(val_size)\n",
        "test_dataset = dataset.skip(val_size).take(test_size)\n",
        "train_dataset = dataset.skip(val_size+test_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scK1mCG8UlcF"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epMFmmGaU7We"
      },
      "source": [
        "def build_embedding_matrix(sequences, word2idx, embedding_dim, embedding_file):\n",
        "    if os.path.exists(embedding_file):\n",
        "        E = np.load(embedding_file)\n",
        "    else:\n",
        "        vocab_size = len(word2idx)\n",
        "        E = np.zeros((vocab_size, embedding_dim))\n",
        "        word_vectors = api.load(EMBEDDING_MODEL)\n",
        "        for word, idx in word2idx.items():\n",
        "            try:\n",
        "                E[idx] = word_vectors.word_vec(word)\n",
        "            except KeyError:\n",
        "                pass\n",
        "        np.save(embedding_file, E)\n",
        "    return E"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMfECdbDWnXw"
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "DATA_DIR = \"/content/data\"\n",
        "EMBEDDING_NUMPY_FILE = os.path.join(DATA_DIR, \"E.npy\")\n",
        "EMBEDDING_MODEL = \"glove-wiki-gigaword-300\"\n",
        "E = build_embedding_matrix(text_sequences, word2idx, EMBEDDING_DIM, EMBEDDING_NUMPY_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCacPo5vlr3A"
      },
      "source": [
        "class SpamClassifierModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedd_size, input_length, num_filters, \n",
        "                 kernel_size, output_size, run_mode, embedding_weights, **kwargs):\n",
        "        super(SpamClassifierModel, self).__init__(**kwargs)\n",
        "\n",
        "        if run_mode == \"scratch\":\n",
        "            self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                       embedd_size, \n",
        "                                                       input_length=input_length, \n",
        "                                                       trainable=False)\n",
        "        elif run_mode == \"vectorizer\":\n",
        "            self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                       embedd_size,\n",
        "                                                       input_length=input_length,\n",
        "                                                       weights=[embedding_weights], \n",
        "                                                       trainable = False)\n",
        "        else:\n",
        "            self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                       embedd_size,\n",
        "                                                       input_length=input_length,\n",
        "                                                       weights=[embedding_weights], \n",
        "                                                       trainable = True)\n",
        "            \n",
        "        self.conv = tf.keras.layers.Conv1D(filters=num_filters, \n",
        "                                           kernel_size=kernel_size, \n",
        "                                           activation=\"relu\")\n",
        "        self.dropout = tf.keras.layers.SpatialDropout1D(0.2)\n",
        "        self.pool = tf.keras.layers.GlobalMaxPooling1D()\n",
        "        self.dense = tf.keras.layers.Dense(output_size, activation=\"softmax\")\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dense(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ3zAewcuiWB"
      },
      "source": [
        "conv_num_filters = 256\n",
        "conv_kernel_size = 3\n",
        "run_modes = [\"scratch\", \"vectorizer\", \"other\"]\n",
        "model = SpamClassifierModel(vocab_size, EMBEDDING_DIM, len(text_sequences[0]), \n",
        "                            conv_num_filters, conv_kernel_size, 2, run_modes[1], \n",
        "                            E)\n",
        "model.build(input_shape=(None, len(text_sequences[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JThaQHOUvmG8"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMxh7L5evx-l",
        "outputId": "79d518a3-d51e-4801-8fe6-1215a0e83a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "EPOCHS = 3\n",
        "CLASS_WEIGHTS = {0:1, 1:8}\n",
        "model.fit_generator(train_dataset, epochs=EPOCHS, validation_data=val_dataset, \n",
        "                    class_weight=CLASS_WEIGHTS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "28/28 [==============================] - 13s 466ms/step - loss: 0.5121 - accuracy: 0.8708 - val_loss: 0.1355 - val_accuracy: 0.9609\n",
            "Epoch 2/3\n",
            "28/28 [==============================] - 13s 465ms/step - loss: 0.1801 - accuracy: 0.9623 - val_loss: 0.0873 - val_accuracy: 0.9668\n",
            "Epoch 3/3\n",
            "28/28 [==============================] - 13s 461ms/step - loss: 0.1059 - accuracy: 0.9844 - val_loss: 0.0489 - val_accuracy: 0.9883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce53407588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaUqldRdwzea",
        "outputId": "05e37d8e-a8e0-485d-d54b-d4d13e2e913a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "labels, predictions = [], []\n",
        "for Xtest, Ytest in test_dataset:\n",
        "    Ytest_ = model.predict_on_batch(Xtest)\n",
        "    ytest = np.argmax(Ytest, axis=1)\n",
        "    ytest_ = np.argmax(Ytest_, axis=1)\n",
        "    labels.extend(ytest.tolist())\n",
        "    predictions.extend(ytest_.tolist())\n",
        "print(\"test accuracy: {:.3f}\".format(accuracy_score(labels,predictions)))\n",
        "print(\"confusion matrix\")\n",
        "print(confusion_matrix(labels, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.987\n",
            "confusion matrix\n",
            "[[1091   14]\n",
            " [   3  172]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3F6rOO23jj-"
      },
      "source": [
        "<h1>Node2Vec and DeepWalk</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOqP2Q-wRM79",
        "outputId": "912c7ba1-f1a9-4864-ded6-2875181c7531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=11fe8b3fd1e86c1109d3df5ecf1131e5c3a26233743d8b5d4b13f8f508c8ab70\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHY-uFmXxaJt"
      },
      "source": [
        "import gensim\n",
        "import logging\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import wget\n",
        "import zipfile\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import  cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9D59S2nQlrs"
      },
      "source": [
        "if not os.path.isdir(\"/content/data\"):\n",
        "    os.mkdir(\"/content/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k16_2XdOPqS8"
      },
      "source": [
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBg9zSRkQTx0"
      },
      "source": [
        "DATA_DIR = \"/content/data\"\n",
        "UIC_DATA_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00371/NIPS_1987-2015.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lehGhT-FQ83B"
      },
      "source": [
        "def download_and_read(url):\n",
        "    local_file = url.split(\"/\")[-1]\n",
        "    wget.download(url, f\"/content/{local_file}\")\n",
        "\n",
        "    # with zipfile.ZipFile(f\"/content/{local_file}\", 'r') as zip_ref:\n",
        "    #     zip_ref.extractall(\"/content\")\n",
        "    row_ids, col_ids, data = [], [], []\n",
        "    rid = 0\n",
        "    i = 0\n",
        "    with open(f\"/content/{local_file}\", 'r') as reader:\n",
        "        for line in reader:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\"\\\"\\\",\"):\n",
        "                continue\n",
        "            counts = np.array([int(x) for x in line.split(\",\")[1:]])\n",
        "            nz_col_ids = np.nonzero(counts)[0]\n",
        "            nz_data = counts[nz_col_ids]\n",
        "            nz_rows_ids = np.repeat(rid, len(nz_col_ids))\n",
        "            rid += 1\n",
        "            row_ids.extend(nz_rows_ids)\n",
        "            col_ids.extend(nz_col_ids)\n",
        "            data.extend(nz_data)\n",
        "    reader.close()\n",
        "    TD = csr_matrix((\n",
        "        np.array(data), (\n",
        "            np.array(row_ids), np.array(col_ids)\n",
        "        )\n",
        "    ), shape=(rid, counts.shape[0]))\n",
        "    return TD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PDbJDyUYbIs"
      },
      "source": [
        "TD = download_and_read(UIC_DATA_URL)\n",
        "E = TD.T * TD\n",
        "E[E>0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fY-tetijyH"
      },
      "source": [
        "TD2 = download_and_read(UIC_DATA_URL)\n",
        "E2 = TD.T * TD"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOuzyySinnTP"
      },
      "source": [
        "# NUM_WALKS_PER_VERTEX = 32\n",
        "# MAX_PATH_LEGNTH = 40\n",
        "# RESTART_PROB = 0.15\n",
        "\n",
        "# RANDOM_WALK_FILE = os.path.join(DATA_DIR, \"random-walk.txt\")\n",
        "\n",
        "# def construct_walks(E, n , alpha, ofile):\n",
        "#     if os.path.exists(ofile):\n",
        "#         print(\"Random walks generated already, skipping.\")\n",
        "#         return\n",
        "#     with open(f\"/content/{local_file}\", 'r') as reader:\n",
        "#         for i in range(E.shape[0]):\n",
        "#             if i % 100 == 0:\n",
        "#                 print(\"{:d} random walks generated from {:d} vertices\".foramt(n *i, i))\n",
        "#             for j in range(n):\n",
        "#                 curr = i \n",
        "#                 walk = [curr]\n",
        "#                 target_nodes = np.nonzeros(E[curr])[0]\n",
        "#                 for k in range()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}